{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141cde65",
   "metadata": {},
   "source": [
    "# [Tutorial] Bayesian Optimization with XGBoost\n",
    "\n",
    "[[Tutorial] Bayesian Optimization with XGBoost](https://www.kaggle.com/code/lucamassaron/tutorial-bayesian-optimization-with-xgboost/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9eaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixing a problem with Skopt (see https://github.com/scikit-optimize/scikit-optimize/issues/981)\n",
    "#!conda install scipy=='1.5.3' --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d2ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ "
     ]
    }
   ],
   "source": [
    "#!conda install scipy=='1.5.3' scikit-learn=='0.23.2' --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47bbdfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyaml>=16.9\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-optimize) (1.7.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-optimize) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-optimize) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-optimize) (1.1.0)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.0.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934dd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "from functools import partial\n",
    "\n",
    "# Suppressing warnings because of skopt verbosity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifier/Regressor\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Data processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data \n",
    "X_train = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "X_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d52cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data as a tabular matrix\n",
    "y_train = X_train.target\n",
    "X_train = X_train.set_index('id').drop('target', axis='columns')\n",
    "X_test = X_test.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratifying the target\n",
    "y_stratified = pd.cut(y_train.rank(method='first'), bins=10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f8750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorizing lower bounds\n",
    "from scipy.stats.mstats import winsorize\n",
    "y_train = np.array(winsorize(y_train, [0.002, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pointing out categorical features\n",
    "categoricals = [item for item in X_train.columns if 'cat' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical data using get_dummies\n",
    "dummies = pd.get_dummies(X_train.append(X_test)[categoricals])\n",
    "X_train[dummies.columns] = dummies.iloc[:len(X_train), :]\n",
    "X_test[dummies.columns] = dummies.iloc[len(X_train): , :]\n",
    "del(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical data using OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])\n",
    "X_test[categoricals] = ordinal_encoder.transform(X_test[categoricals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection (https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap)\n",
    "important_features = ['cat8_E', 'cont0', 'cont5', 'cont7', 'cont8', 'cat1_A', 'cont2', 'cont13', \n",
    "                      'cont3', 'cont10', 'cont1', 'cont9', 'cont11', 'cat1', 'cat8_C', 'cont6', \n",
    "                      'cont12', 'cat5', 'cat3_C', 'cont4', 'cat8']\n",
    "\n",
    "X_train = X_train[important_features]\n",
    "X_test = X_test[important_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60424312",
   "metadata": {},
   "source": [
    "### Setting up optimization¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting util for different optimizers\n",
    "def report_perf(optimizer, X, y, title=\"model\", callbacks=None):\n",
    "    \"\"\"\n",
    "    A wrapper for measuring time and performances of different optmizers\n",
    "    \n",
    "    optimizer = a sklearn or a skopt optimizer\n",
    "    X = the training set \n",
    "    y = our target\n",
    "    title = a string label for the experiment\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    \n",
    "    if callbacks is not None:\n",
    "        optimizer.fit(X, y, callback=callbacks)\n",
    "    else:\n",
    "        optimizer.fit(X, y)\n",
    "        \n",
    "    d=pd.DataFrame(optimizer.cv_results_)\n",
    "    best_score = optimizer.best_score_\n",
    "    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "    best_params = optimizer.best_params_\n",
    "    \n",
    "    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "           + u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "                                   len(optimizer.cv_results_['params']),\n",
    "                                   best_score,\n",
    "                                   best_score_std))    \n",
    "    print('Best parameters:')\n",
    "    pprint.pprint(best_params)\n",
    "    print()\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ef7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the scoring function\n",
    "scoring = make_scorer(partial(mean_squared_error, squared=False), \n",
    "                      greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c378f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the validation strategy\n",
    "skf = StratifiedKFold(n_splits=7,\n",
    "                      shuffle=True, \n",
    "                      random_state=0)\n",
    "\n",
    "cv_strategy = list(skf.split(X_train, y_stratified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the basic regressor\n",
    "reg = XGBRegressor(random_state=0, booster='gbtree', objective='reg:squarederror', tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the search space\n",
    "search_spaces = {'learning_rate': Real(0.01, 1.0, 'uniform'),\n",
    "                 'max_depth': Integer(2, 12),\n",
    "                 'subsample': Real(0.1, 1.0, 'uniform'),\n",
    "                 'colsample_bytree': Real(0.1, 1.0, 'uniform'), # subsample ratio of columns by tree\n",
    "                 'reg_lambda': Real(1e-9, 100., 'uniform'), # L2 regularization\n",
    "                 'reg_alpha': Real(1e-9, 100., 'uniform'), # L1 regularization\n",
    "                 'n_estimators': Integer(50, 5000)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698163a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping everything up into the Bayesian optimizer\n",
    "opt = BayesSearchCV(estimator=reg,                                    \n",
    "                    search_spaces=search_spaces,                      \n",
    "                    scoring=scoring,                                  \n",
    "                    cv=cv_strategy,                                           \n",
    "                    n_iter=120,                                       # max number of trials\n",
    "                    n_points=1,                                       # number of hyperparameter sets evaluated at the same time\n",
    "                    n_jobs=1,                                         # number of jobs\n",
    "                    iid=False,                                        # if not iid it optimizes on the cv score\n",
    "                    return_train_score=False,                         \n",
    "                    refit=False,                                      \n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},        # optmizer parameters: we use Gaussian Process (GP)\n",
    "                    random_state=0)                                   # random state for replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the optimizer\n",
    "overdone_control = DeltaYStopper(delta=0.0001)                    # We stop if the gain of the optimization becomes too small\n",
    "time_limit_control = DeadlineStopper(total_time=60*60*4)          # We impose a time limit (7 hours)\n",
    "\n",
    "best_params = report_perf(opt, X_train, y_train,'XGBoost_regression', \n",
    "                          callbacks=[overdone_control, time_limit_control])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521fa3b",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf89bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transferring the best parameters to our basic regressor\n",
    "reg = XGBRegressor(random_state=0, booster='gbtree', objective='reg:squarederror', tree_method='gpu_hist', **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c377cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation prediction\n",
    "folds = 10\n",
    "skf = StratifiedKFold(n_splits=folds,\n",
    "                      shuffle=True, \n",
    "                      random_state=0)\n",
    "\n",
    "predictions = np.zeros(len(X_test))\n",
    "rmse = list()\n",
    "\n",
    "for k, (train_idx, val_idx) in enumerate(skf.split(X_train, y_stratified)):\n",
    "    reg.fit(X_train.iloc[train_idx, :], y_train[train_idx])\n",
    "    val_preds = reg.predict(X_train.iloc[val_idx, :])\n",
    "    val_rmse = mean_squared_error(y_true=y_train[val_idx], y_pred=val_preds, squared=False)\n",
    "    print(f\"Fold {k} RMSE: {val_rmse:0.5f}\")\n",
    "    rmse.append(val_rmse)\n",
    "    predictions += reg.predict(X_test).ravel()\n",
    "    \n",
    "predictions /= folds\n",
    "print(f\"repeated CV RMSE: {np.mean(rmse):0.5f} (std={np.std(rmse):0.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the submission\n",
    "submission = pd.DataFrame({'id':X_test.index, \n",
    "                           'target': predictions})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5475221",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
