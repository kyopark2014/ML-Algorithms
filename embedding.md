# Embedding

자연어를 컴퓨터가 처리하도록 하기 위해서 숫자로 바꾸는 방법을 알아야 합니다. 문자를 기계가 이해할 수 있는 숫자로 바꾼 결과 또는 그 과정을 임베딩(Embedding)이라고 합니다. 

- 고정된 크기의 실수 벡터로 변환합니다.
- 실수값의 크기가 의미를 가지므로 단어간의 관계 표현이 가능합니다.
- 실수값은 임의로 정하지 않고 데이터를 이용해 학습하여 구합니다. 


## One-Hot Encoding

가장 간단한 형태의 임베딩은 문장에 어떤 단어가 많이 쓰였는지를 파악하여 글쓴이의 의도를 알 수 있습니다. 원-핫 인코딩(One-Hot Encoding)은 여러 기법 중 단어를 표현하는 가장 기본적인 표현 방법입니다.

원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 벡터 표현 방식입니다. 이렇게 표현된 벡터를 원-핫 벡터(One-Hot Vector)라고 합니다. 텍스트를 숫자로 표현하는 대표적인 방법으로 하나의 1과 수많은 0으로 표현하는 방법인데, 예문을 통해 이해해보도록 하겠습니다.

## Word2Vec

Embedding의 하나의 방법으로 [Word2Vec](https://word2vec.kr/search/)가 있는데, "한국-서울+도쿄"로 입력하면 아래와 같은 결과를 얻을 수 있습니다. 

![image](https://user-images.githubusercontent.com/52392004/188033702-4562c422-0653-466c-8929-7a6a684d3252.png)



## Reference 

[Machine Learning at Work - 한빛미디어]

[AI4SCHOOL 언어와 소통 – 5. 자연어처리 기법](http://ai4school.org/?page_id=2407)
