{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8efd37",
   "metadata": {},
   "source": [
    "# 8.6 안전 운전자 예측 경진대회 성능 개선 III : LightGBM과 XGBoost 앙상블\n",
    "\n",
    "[[ch8] Ensemble](https://www.kaggle.com/code/werooring/ch8-ensemble/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f27fd",
   "metadata": {},
   "source": [
    "[안전 운전자 예측 경진대회 링크](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)\n",
    "\n",
    "[탐색적 데이터 분석 코드 참고 링크](https://www.kaggle.com/code/bertcarremans/data-preparation-exploration/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee08b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = './porto-seguro-safe-driver-prediction/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
    "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3da761",
   "metadata": {},
   "source": [
    "### 8.4.1 피처 엔지니어링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d538c91",
   "metadata": {},
   "source": [
    "### 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca76530",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "all_data = all_data.drop('target', axis=1) # 타깃값 제거\n",
    "\n",
    "all_features = all_data.columns # 전체 피처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ced4d",
   "metadata": {},
   "source": [
    "### 명목형 피처 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59903fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 명목형 피처\n",
    "cat_features = [feature for feature in all_features if 'cat' in feature] \n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5489d9f",
   "metadata": {},
   "source": [
    "### 파생 피처 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5752e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '데이터 하나당 결측값 개수'를 파생 피처로 추가\n",
    "all_data['num_missing'] = (all_data==-1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9b36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명목형 피처, calc 분류의 피처를 제외한 피처\n",
    "remaining_features = [feature for feature in all_features\n",
    "                      if ('cat' not in feature and 'calc' not in feature)] \n",
    "# num_missing을 remaining_features에 추가\n",
    "remaining_features.append('num_missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab08c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류가 ind인 피처\n",
    "ind_features = [feature for feature in all_features if 'ind' in feature]\n",
    "\n",
    "is_first_feature = True\n",
    "for ind_feature in ind_features:\n",
    "    if is_first_feature:\n",
    "        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n",
    "        is_first_feature = False\n",
    "    else:\n",
    "        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c395663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n",
       "1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n",
       "2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n",
       "3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n",
       "4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n",
       "                           ...                  \n",
       "1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n",
       "1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n",
       "1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n",
       "1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n",
       "1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\n",
       "Name: mix_ind, Length: 1488028, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['mix_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc0497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_features = []\n",
    "for feature in cat_features+['mix_ind']:\n",
    "    val_counts_dict = all_data[feature].value_counts().to_dict()\n",
    "    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: \n",
    "                                                           val_counts_dict[x])\n",
    "    cat_count_features.append(f'{feature}_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f80b16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_02_cat_count',\n",
       " 'ps_ind_04_cat_count',\n",
       " 'ps_ind_05_cat_count',\n",
       " 'ps_car_01_cat_count',\n",
       " 'ps_car_02_cat_count',\n",
       " 'ps_car_03_cat_count',\n",
       " 'ps_car_04_cat_count',\n",
       " 'ps_car_05_cat_count',\n",
       " 'ps_car_06_cat_count',\n",
       " 'ps_car_07_cat_count',\n",
       " 'ps_car_08_cat_count',\n",
       " 'ps_car_09_cat_count',\n",
       " 'ps_car_10_cat_count',\n",
       " 'ps_car_11_cat_count',\n",
       " 'mix_ind_count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_count_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3a67e",
   "metadata": {},
   "source": [
    "### 필요 없는 피처 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc10dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "# 필요 없는 피처들\n",
    "drop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', \n",
    "                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n",
    "\n",
    "# remaining_features, cat_count_features에서 drop_features를 제거한 데이터\n",
    "all_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n",
    "\n",
    "# 데이터 합치기\n",
    "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n",
    "                               encoded_cat_matrix],\n",
    "                              format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822d14b",
   "metadata": {},
   "source": [
    "### 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66fa2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "X = all_data_sprs[:num_train]\n",
    "X_test = all_data_sprs[num_train:]\n",
    "\n",
    "y = train['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368dd8e5",
   "metadata": {},
   "source": [
    "### 정규화 지니계수 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29179d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def eval_gini(y_true, y_pred):\n",
    "    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    n_samples = y_true.shape[0]                      # 데이터 개수\n",
    "    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n",
    "\n",
    "    # 1) 예측값에 대한 지니계수\n",
    "    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
    "    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n",
    "\n",
    "    # 2) 예측이 완벽할 때 지니계수\n",
    "    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n",
    "    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n",
    "\n",
    "    # 정규화된 지니계수\n",
    "    return G_pred / G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb2a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM용 gini() 함수\n",
    "def gini_lgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', eval_gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c85d63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost용 gini() 함수\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', eval_gini(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18e0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기 생성\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf47aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_lgb = {\n",
    "    'bagging_fraction': 0.6213108174593661,\n",
    "    'feature_fraction': 0.608712929970154,\n",
    "    'lambda_l1': 0.7040436794880651,\n",
    "    'lambda_l2': 0.9832619845547939,\n",
    "    'min_child_samples': 9,\n",
    "    'min_child_weight': 36.10036444740457,\n",
    "    'num_leaves': 40,\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.005,\n",
    "    'bagging_freq': 1,\n",
    "    'force_row_wise': True,\n",
    "    'random_state': 1991\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937133ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 폴드 1 / 폴드 5 ########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n",
      "[LightGBM] [Info] Total Bins 1554\n",
      "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n",
      "[LightGBM] [Info] Start training from score -3.274764\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.154239\tvalid_0's gini: 0.270944\n",
      "[200]\tvalid_0's binary_logloss: 0.153176\tvalid_0's gini: 0.275764\n",
      "[300]\tvalid_0's binary_logloss: 0.152584\tvalid_0's gini: 0.279501\n",
      "[400]\tvalid_0's binary_logloss: 0.152222\tvalid_0's gini: 0.282893\n",
      "[500]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.286058\n",
      "[600]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.288805\n",
      "[700]\tvalid_0's binary_logloss: 0.151712\tvalid_0's gini: 0.290719\n",
      "[800]\tvalid_0's binary_logloss: 0.151622\tvalid_0's gini: 0.292581\n",
      "[900]\tvalid_0's binary_logloss: 0.151552\tvalid_0's gini: 0.294212\n",
      "[1000]\tvalid_0's binary_logloss: 0.151505\tvalid_0's gini: 0.295204\n",
      "[1100]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.295909\n",
      "[1200]\tvalid_0's binary_logloss: 0.151438\tvalid_0's gini: 0.296721\n",
      "[1300]\tvalid_0's binary_logloss: 0.151414\tvalid_0's gini: 0.297335\n",
      "[1400]\tvalid_0's binary_logloss: 0.151402\tvalid_0's gini: 0.297569\n",
      "[1500]\tvalid_0's binary_logloss: 0.15139\tvalid_0's gini: 0.297881\n",
      "[1600]\tvalid_0's binary_logloss: 0.151382\tvalid_0's gini: 0.298033\n",
      "[1700]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.298238\n",
      "[1800]\tvalid_0's binary_logloss: 0.151372\tvalid_0's gini: 0.298342\n",
      "[1900]\tvalid_0's binary_logloss: 0.151369\tvalid_0's gini: 0.298371\n",
      "[2000]\tvalid_0's binary_logloss: 0.151371\tvalid_0's gini: 0.298222\n",
      "[2100]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298463\n",
      "[2200]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298466\n",
      "[2300]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298415\n",
      "[2400]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298569\n",
      "[2500]\tvalid_0's binary_logloss: 0.151361\tvalid_0's gini: 0.298542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2458]\tvalid_0's binary_logloss: 0.151355\tvalid_0's gini: 0.29865\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds_lgb = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds_lgb = np.zeros(X_test.shape[0]) \n",
    "\n",
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # LightGBM 전용 데이터셋 생성\n",
    "    dtrain = lgb.Dataset(X_train, y_train) # LightGBM 전용 훈련 데이터셋\n",
    "    dvalid = lgb.Dataset(X_valid, y_valid) # LightGBM 전용 검증 데이터셋\n",
    "                          \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=max_params_lgb,     # 최적 하이퍼파라미터\n",
    "                          train_set=dtrain,          # 훈련 데이터셋\n",
    "                          num_boost_round=2500,      # 부스팅 반복 횟수\n",
    "                          valid_sets=dvalid,         # 성능 평가용 검증 데이터셋\n",
    "                          feval=gini_lgb,            # 검증용 평가지표\n",
    "                          early_stopping_rounds=300, # 조기종료 조건\n",
    "                          verbose_eval=100)          # 100번째마다 점수 출력\n",
    "    \n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "    oof_test_preds_lgb += lgb_model.predict(X_test)/folds.n_splits\n",
    "    \n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n",
    "    oof_val_preds_lgb[valid_idx] += lgb_model.predict(X_valid)\n",
    "    \n",
    "    # 검증 데이터 예측확률에 대한 정규화 지니계수\n",
    "    gini_score = eval_gini(y_valid, oof_val_preds_lgb[valid_idx])\n",
    "    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_xgb = {\n",
    "    'colsample_bytree': 0.8843124587484356,\n",
    "    'gamma': 10.452246227672624,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 6.494091293383359,\n",
    "    'reg_alpha': 8.551838810159788,\n",
    "    'reg_lambda': 1.3814765995549108,\n",
    "    'scale_pos_weight': 1.423280772455086,\n",
    "    'subsample': 0.7001630536555632,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.02,\n",
    "    'random_state': 1991\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6589e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds_xgb = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds_xgb = np.zeros(X_test.shape[0]) \n",
    "\n",
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "    # XGBoost 전용 데이터셋 생성 \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    # XGBoost 모델 훈련\n",
    "    xgb_model = xgb.train(params=max_params_xgb, \n",
    "                          dtrain=dtrain,\n",
    "                          num_boost_round=2000,\n",
    "                          evals=[(dvalid, 'valid')],\n",
    "                          maximize=True,\n",
    "                          feval=gini_xgb,\n",
    "                          early_stopping_rounds=200,\n",
    "                          verbose_eval=100)\n",
    "\n",
    "    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n",
    "    best_iter = xgb_model.best_iteration\n",
    "\n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "    oof_test_preds_xgb += xgb_model.predict(dtest,\n",
    "                                            iteration_range=(0, best_iter))/folds.n_splits\n",
    "    \n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n",
    "    oof_val_preds_xgb[valid_idx] += xgb_model.predict(dvalid, \n",
    "                                                      iteration_range=(0, best_iter))\n",
    "    \n",
    "    # 검증 데이터 예측확률에 대한 정규화 지니계수\n",
    "    gini_score = eval_gini(y_valid, oof_val_preds_xgb[valid_idx])\n",
    "    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9677010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LightGBM OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('XGBoost OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4886323",
   "metadata": {},
   "source": [
    "### 8.6.1 앙상블 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_test_preds = oof_test_preds_lgb * 0.5 + oof_test_preds_xgb * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc41449",
   "metadata": {},
   "source": [
    "### 8.6.2 예측 및 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = oof_test_preds\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
